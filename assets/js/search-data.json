{
  
    
        "post0": {
            "title": "Handle C++ exceptions in C code, part 1",
            "content": "Hold on! Before you call me crazy, please let me clarify. Yes, I am going to tell you how to handle C++ exceptions in C code, but don&#39;t worry, I know this is a terrible idea, and (hopefully) no one is actually going to do that. . But why, you might ask, would anyone even begin to ponder such a silly idea? Well, poking things and making them do things they aren&#39;t supposed to do is a brilliant way to figure out how they work. And exception handling is certainly a very interesting , and perhaps quite important, practical computer algorithm. So it&#39;s quite natural for someone to have curiosity about how it works. . Alright. But where do we even start? If you search for information on exception handling online, what you would find is usually cryptic and incomplete documentation about ELF, Dwarf, and C++ ABI. Often they are difficult to understand, and it is usually hard for someone to see how they all fit together. . So instead, let&#39;s work in reverse. Let&#39;s inspect something that actually does exception handling. . int throw_exception() { throw nullptr; } int main() { try { throw_exception(); } catch (void *e){ } } . This is a baseline program that throws an exception and catches it. Let&#39;s try compiling it and see what comes out: . g++ code.cc -S . If you are wondering what -S does, it tells the compiler to stop after producing the assembly, without assembling or linking the code. You should try this step yourself, and look at the assembly produced. Here, I picked out a few relevant snippets, and simplified them to make them easier to read. . Let&#39;s look at the throwing side first: . throw_exception(): .LFB0: push rbp mov rbp, rsp mov edi, 8 call __cxa_allocate_exception@PLT ; &lt;- mov QWORD PTR [rax], 0 mov edx, 0 lea rsi, _ZTIDn[rip] mov rdi, rax call __cxa_throw@PLT ; &lt;- . If you are not used to looking at assembly, this might look quite daunting. But luckily, you don&#39;t have to know any assembly at all to pick out the interesting bits here: __cxa_allocate_exception and __cxa_throw. . As their names suggest, __cxa_allocate_exception allocates space for the thrown exception, and __cxa_throw actually commences the throwing. (the __cxa_ bit probably means &quot;cxx abi&quot;, I am not sure.) You don&#39;t have to take my words, you can find this information here. . If you are curious, you can find the code of __cxa_throw here. For the rest of us, we are move on to the catching side: . main: .LFB1: push rbp mov rbp, rsp sub rsp, 16 .LEHB0: call throw_exception() .LEHE0: .L6: mov eax, 0 jmp .L8 ; &lt;- this will jump to the label below .L7: cmp rdx, 1 je .L5 mov rdi, rax .LEHB1: call _Unwind_Resume@PLT .LEHE1: .L5: mov rdi, rax call __cxa_begin_catch@PLT mov QWORD PTR -8[rbp], rax call __cxa_end_catch@PLT jmp .L6 .L8: ; &lt;- this is a label leave ret ; &lt;- this means &quot;return&quot; . (If you don&#39;t know how to read this assembly, you just need to know this: instructions which start with letter j mean jump. The thing which follows the jump instruction is a &quot;label&quot;, which is also what the .Lxxx: you see in the code are. The jump instruction will jump to the matching label when executed) . OK, here we spot __cxa_begin_catch and __cxa_end_catch, which seems to be relevant. However, they don&#39;t seem to be directly reachable. If you follow the call to throw_exception(), you can see after it returns, the code immediately jumps to .L8, then returns from main. So who is going to execute the catch block? . Let&#39;s look a bit further into the assembly: . .LFE1: .globl __gxx_personality_v0 .section .gcc_except_table,&quot;a&quot;,@progbits .align 4 .LLSDA1: .byte 0xff .byte 0x9b .uleb128 .LLSDATT1-.LLSDATTD1 .LLSDATTD1: .byte 0x1 .uleb128 .LLSDACSE1-.LLSDACSB1 .LLSDACSB1: .uleb128 .LEHB0-.LFB1 .uleb128 .LEHE0-.LEHB0 .uleb128 .L7-.LFB1 ; &lt;- ha .uleb128 0x1 .uleb128 .LEHB1-.LFB1 .uleb128 .LEHE1-.LEHB1 .uleb128 0 .uleb128 0 . This assembly block defines data. After being assembled and linked, they become data bytes stored verbatim in the executable. And in there, we find a reference to .L7. Look back at the code, we can see .L7 contains a jump to .L5, which is the catch block. . From this, we can infer that, there is some information stored in the executable (&quot;metadata&quot;), which the exception throwers will read when they throw an exception, to figure out what code to run when they throw an exception. . Alright, we have a rough picture of how exception handling works: . The thrower prepares the exception, then call __cxa_throw | __cxa_throw looks through the metadata of the callers in the function call stack, to find a suitable catcher | The program jumps to the catcher | . Looks simple, right? If we can somehow make the metadata of a C function yell: &quot;hey, look here, I am an exception catcher!&quot;, we will be done here. . But, as you might know, there is no such thing as exceptions in the C language. There can&#39;t possibly be a way to declare a function as exception catcher, right? . Well, there is not a standard way. But there is a way. There is this extension to C, implemented by the GCC compiler (and later Clang), which allows you to attach a &quot;cleanup&quot; function to a local variable. This cleanup function will be called when the local variable goes out of scope. . Because of the excellent interoperability between C and C++, you can have the situation where an C++ exception is thrown &quot;through&quot; a C function. Normally, the cleanup functions aren&#39;t going to run in that case. However, this makes people unhappy. So, now, there is a way to make them run. . Passing the -fexceptions option to GCC, makes it generate exception-aware code even when compiling C code. And in that mode, the cleanup functions will be registered as exception handlers! Just like the destructors of local variables in C++. . Here is an example: . // file1.cc extern &quot;C&quot; void throw_exception() { throw nullptr; } extern &quot;C&quot; void might_throw(); int main() { try { // OK, we have to have a try/catch in main, // because if C++ cannot find an actual `catch` block, // it will just abort(), without going through the throw // process at all. might_throw(); } catch (void *e) { } } . // file2.c #include &lt;stdio.h&gt; extern void throw_exception(); void a_cleanup_function(void *x) { fprintf(stderr, &quot;cleanup called n&quot;); } void might_throw() { // Call a_cleanup_function when `x` goes out of scope __attribute__((cleanup(a_cleanup_function))) int x; throw_exception(); fprintf(stderr, &quot;do more stuff n&quot;); // we don&#39;t get to this point :&#39;( } . Compile and run: . g++ file1.cc -c gcc file2.c -fexceptions -c g++ file1.o file2.o ./a.out . You will see it says: . cleanup called . If you look at the assembly of file2.c, you will see structures very similar to the try/catch block in file1.cc. . OK, we are able to get a C function called during the handling of a C++ exception. But this exception still propagated through the C function, why? . Let&#39;s look at the assembly again: . might_throw: ; ... skipped ... .L7: mov rbp, rax jmp .L5 .L5: lea rdi, 4[rsp] .LEHB2: call a_cleanup_function mov rdi, rbp call _Unwind_Resume@PLT ; ... more skipped ... . Here you can easily see the call to a_cleanup_function, right after that, is a call to _Unwind_Resume. What does that do? . First of all, what does &quot;unwind&quot; mean here? You might have already known, the program needs to &quot;unwind its stack&quot; when an exception is thrown. Basically it has to remove entries on its call stack, until a catcher is found. Which is the process we already described above. . So, inferring from the name again, we can guess that _Unwind_Resume will resume an interrupted stack unwinding (which is correct, by the way). And our cleanup function does interrupt the unwind, so after it returns, the program calls _Unwind_Resume to resume it. . Alright, if, we can stop that function from being called. If we can do that, we would have &quot;caught&quot; the exception. . Basically, we want a_cleanup_function to skip over everything in might_throw that is after the call to a_cleanup_function. Clearly, we need something that could interrupt the normal execution flow of the program. goto is not enough, because our skip is cross-function. We need something stronger. . And there is indeed something stronger. setjmp and longjmp! A call to longjmp allows you to jump to a point in the program where you have previously called setjmp (the man page explains these functions very well). So we just need to use setjmp to put an anchor in the normal return path of might_throw, then have a_cleanup_function jump to there with longjmp, and we would have skipped the _Unwind_Resume. . Here is a version of might_throw that does this: . #include &lt;setjmp.h&gt; struct Catch { jmp_buf env; // The cleanup function will be called when the exception is thrown, // but then it will be called again when we return from `might_throw`. // We don&#39;t want it to perform the longjmp when `might_throw` is returning // normally, so we use a flag to indicate whether a longjmp should be // performed. int do_jump; }; void a_cleanup_function(struct Catch *env) { if (env-&gt;do_jump) { longjmp(env-&gt;env, 1); } } void might_throw() { __attribute__((cleanup(a_cleanup_function))) struct Catch env; if (setjmp(env.env) == 0) { env.do_jump = 1; throw_exception(); } else { fprintf(stderr, &quot;exception caught n&quot;); env.do_jump = 0; } fprintf(stderr, &quot;do more stuff after having caught the exception n&quot;); } . And running it, we will get: . exception caught do more stuff after having caught the exception . Voilà! We have caught a C++ exception in C. . OK, are we done? . No! This result might be good enough, but I am still not satisfied. We have successfully stopped an exception in C code, but we don&#39;t actually get the thing that was thrown. All we know in our &quot;exception handler&quot; is an exception was thrown, but not what the exception is. This is quite useless. . So, can we retrieve the thrown exception? . Maybe. We will continue in part 2. .",
            "url": "https://explain.yshui.dev/programming%20language/2020/10/16/exceptions.html",
            "relUrl": "/programming%20language/2020/10/16/exceptions.html",
            "date": " • Oct 16, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "How you could have come up with Paxos yourself",
            "content": "In the field of computer science, the Paxos algorithm is notorious for how difficult it is to understand. I had to learn the Paxos algorithm in my distributed systems class. I even have &quot;implemented&quot; it by translating Leslie Lamport&#39;s TLA+ to Python. But I didn&#39;t understand it until much much later. . Now I have a better understanding of Paxos than I used to, I want to explain it to other people. Not because I&#39;d like to help people, rather, I find that explaining things is a very good way to find blind spots in my own understanding. . So, where do we start? Personally, I dislike explanations that start with a step-by-step breakdown of the algorithm, followed by a proof of why those steps do what they claim to do. Instead, I much prefer to start with the problem the algorithm tries to solve, then iteratively come up with a solution together with the reader. So that&#39;s what I am going to do. And now you understand the title. . Small disclaimer: The glossaries used in this article is different from what is commonly used for Paxos. I just picked the ones that made the most sense for my narrative. . The problem . The distributed consensus problem is widely useful, so the reader probably doesn&#39;t need to be motivated. Here I will just simply state the problem. . There is a group of agents (let&#39;s call them $ sc{CLIENT}s$), who want to choose a number among their selections. Any number is fine, as long as everyone agrees on the same number. . Here, there are a few assumptions we will make to make this problem meaningful: . All the agents - including but not limited to the $ sc{CLIENT}s$, as we will add more types of agents later - are well-behaved. Meaning they all execute the prescribed algorithms faithfully, and don&#39;t maliciously try to trick other agents. (If you like jargons: Byzantine failures don&#39;t occur.) | Agents can talk to each other by sending each other messages, but the messages they send to each other could take arbitrarily long before reaching their destination, and might get lost (but never altered). | . The agents could also &quot;fail&quot;. However, failing is equivalent to all messages sent to/from that agent being lost forever. So whether we have this assumption or not won&#39;t change the algorithm we come up with. . Also, to not complicate things, we are only solving the &quot;single-round&quot; consensus problem in this article, meaning as the output of this algorithm, all of the $ sc{CLIENT}s$ will get a single number which they agree on. . Solution searching adventure . Iteration 0 . When trying to solve a complex problem such as this one, it&#39;s usually a good idea to start by simplifying the problem. As a start, let&#39;s just ignore the need to be reliable entirely. . If we throw reliability out the window, it should be easy to come up with a very simple solution: we add an agent (let&#39;s call it $ sc{COORDINATOR}$). The $ sc{CLIENTS}$ send whatever number they pick to the $ sc{COORDINATOR}$ in a $ sc{PROPOSAL}(client_i, x)$ message, where $x$ is the number proposed by the $i$-th $ sc{CLIENT}$. The $ sc{COORDINATOR}$ picks an arbitrary proposal (say, $x&#39;$), and informs the other $ sc{CLIENT}s$ about this decision. Specifically, the $ sc{COORDINATOR}$ will just reply with a $ sc{CHOSEN}(x&#39;)$ message to all the $ sc{PROPOSAL}( ldots)$ messages it has received and will receive. . If we assume no messages ever get lost, it is quite easy to see that every $ sc{CLIENT}$ will get a number. And because only one number is ever chosen, they will all get the same number. . It is also easy to see why this solution is impractical: it has a single point of failure. Once the singular $ sc{COORDINATOR}$ fails, no further progress can be made. . Iteration 1 . To improve this almost looks easy at first glance: just add more $ sc{COORDINATOR}s$! . Sure, more $ sc{COORDINATOR}s$ would remove the single point of failure. However, if there are more than one $ sc{COORDINATOR}s$, they might individually make different decisions, which results in the $ sc{CLIENT}s$ having disagreement. . What if we let the $ sc{COORDINATOR}s$ reach an agreement among themselves before responding? But wait, doesn&#39;t that sound familiar? Having a group of agents reaching an agreement, that&#39;s exactly what we added the $ sc{COORDINATOR}s$ to solve. We just made the problem cyclic. . Let&#39;s take a step back. Is there a way for the clients to reach an agreement without having the $ sc{COORDINATOR}s$ communicate with each other? . In other words, among the decisions of the $ sc{COORDINATOR}s$, is there an deterministic algorithm to pick out a specific one that is robust against message losses? . This might sound hard, but it&#39;s actually quite simple: pick the decision that is backed by more than half of the $ sc{COORDINATOR}s$. . There can&#39;t be two decisions both with more than half of the $ sc{COORDINATOR}s$ backing them; and if a decision doesn&#39;t have that many $ sc{COORDINATOR}s$ backing it, it won&#39;t appear to have more backing $ sc{COORDINATOR}s$ through message losses. . Since this approach resembles a majority vote, let&#39;s call $ sc{COORDINATOR}$ decisions $ sc{VOTE}(coord_i, x)$ from now on, where $x$ is the number picked by the $i$-th $ sc{COORDINATOR}$. Each $ sc{COORDINATOR}$ has a single vote, because each of them only makes a single decision. . Obviously, our solution cannot be infinitely reliable. If more than half of the $ sc{COORDINATOR}s$ went down, there will never be a majority reached. But this is already vastly better than our first solution, and the reliability scales with the number of $ sc{COORDINATOR}s$. So we will call it good enough. . Sadly, this solution doesn&#39;t actually work: there might not be a majority at all! For example, it&#39;s possible that three of the proposals each get a third of the votes. We would have a stalemate in that case. . Iteration 2 . Again, a solution seems straightforward: just try again in case of a stalemate. . But then again, things aren&#39;t that simple. . First of all, the $ sc{COORDINATOR}s$ need to be made aware of a retry. Otherwise, because each $ sc{COORDINATOR}$ only has one vote, they won&#39;t be able to vote again even if the $ sc{CLIENT}s$ retry. . To do that, we attach an attempt id to all the messages sent. i.e. $ sc{PROPOSAL}(client_i, x)$ becomes $ sc{PROPOSAL}( #attempt, client_i, x)$, and so forth. Each time a $ sc{CLIENT}$ retries, it bumps $ #attempt$ to the maximum $ #attempt$ it knows of plus 1. And the $ sc{COORDINATOR}s$ should only responds to messages with the most recent $ #attempt$. . Hopefully the intent of the $ #attempt$ number is clear. (Let me know if not.) . Are we good now? Unfortunately, no. Consider this scenario: . There were 2 clients. They proposed their numbers, the $ sc{COORDINATOR}$ voted on them and all agreed on a single number, $x_1$, all is good. But, all of the $ sc{VOTE}( ldots)$ messages got lost on the way to $client_2$, while $client_1$ received all of the messages just fine. At this point, $client_1$ thought $x_1$ is the number, but $client_2$ went on to retry. The $ sc{COORDINATOR}s$ voted again, and got $x_2$. This time, all the messages sent to $client_1$ got lost. . And behold, we got the two clients to disagree. . There is an important insight to be had here. Whenever a $ sc{COORDINATOR}$, say $coord_i$, sends out a $ sc{VOTE}( ldots, coord_i, x)$, there is a chance that some $ sc{CLIENT}$ would adopt $x$. If $coord_i$ ever sends out two votes with different $x$, there is a chance that some of the $ sc{CLIENT}s$ would disagree. . In other words, once a $ sc{COORDINATOR}$ has revealed its vote, it has to stick to it. . This seems to run contrary to our attempt: if the $ sc{COORDINATOR}s$ cannot change their votes, what&#39;s the point of retrying? A stalemate will be a stalemate forever. . Looks like we reached a dead end with this type of voting. It appears the problem stems from the fact that the $ sc{COORDINATOR}s$ have to commit to their votes. . So, what if we introduce a form of non-commitment voting? . Iteration 3 . Let&#39;s explore this idea. Say, the $ sc{COORDINATOR}s$ could now send a $ sc{TENTATIVE} sc{VOTE}( #attempt, coord_i, x)$ message, to tentatively vote for $x$. . Obviously, the $ sc{CLIENT}s$ couldn&#39;t adopt $x$ right away. So what&#39;s this vote good for? . Ah, right, it could get us to a majority. . It is correct that tentative votes don&#39;t lead directly to an agreement among $ sc{CLIENT}s$, but it can show us when a majority has formed among the $ sc{COORDINATOR}s$. . Once a $ sc{CLIENT}$ sees a majority tentative vote, it can then message the $ sc{COORDINATOR}s$ to ask for an actual vote. (Let&#39;s call this message $ sc{PLEASE} sc{VOTE}( #attempt, client_i)$). Intuitively, the $ sc{COORDINATOR}s$ have to make the same vote in the actual vote as their tentative votes. . If all goes well, we would get a majority and an agreement. If there is no majority, the $ sc{COORDINATOR}s$ won&#39;t even start a vote, so they are free to change their mind. So the $ sc{CLIENT}s$ could start another attempt which might have a different outcome. . What if things don&#39;t go well? What if the $ sc{PLEASE} sc{VOTE}$ messages weren&#39;t received by some of the $ sc{COORDINATOR}s$? In that case, some of the $ sc{COORDINATOR}s$ would have voted, and their decisions cannot be changed. That is to say, in all subsequent attempts, these $ sc{COORDINATOR}s$ will always vote for what they have voted for, whether it&#39;s a tentative vote, or the actual vote. But that doesn&#39;t create a problem for us. There was a majority in the tentative votes, and now we solidified part of the tentative votes. There is at least one way we can still reach a majority in the next round: everyone votes the same as they did in this round. And we can prove this inductively for all future rounds. . From this, we can have a rough image of how the algorithm functions: as attempts are being made, more and more $ sc{COORDINATOR}s$ start to make up their mind which number they will commit to, while making sure a majority could still be reached. Eventually, after all the $ sc{COORDINATOR}s$ have made up their minds, by induction there must be a majority among them. From that point on, they will just repeatedly broadcast this decision to the $ sc{CLIENT}s$, until all the $ sc{CLIENT}s$ have got that message. . And Viola, we have a working algorithm. . The actual algorithm . Let&#39;s clean up our thoughts, and condense the description of our algorithm so it&#39;s easy to understand. . First, there is the $ #attempt$ number that is attached to every message. This number is bumped every time a new attempt is made. If a $ sc{CLIENT}$ sees a message with a $ #attempt$ bigger then its most recent $ #attempt$, it knows a new attempt has been initiated, so it would abort its current attempt and participate in the newer one. If a $ sc{COORDINATOR}$ sees a message with a $ #attempt$ smaller than the biggest $ #attempt$ it has ever seen, it would know that message is stale, so it will drop the message. . With that out of the way, let&#39;s describe what happens in an attempt. . Each attempt can be split into two phases: . Phase 1: The $ sc{CLIENT}s$ each send its $ sc{PROPOSAL}( ldots)$ to the $ sc{COORDINATOR}s$. The $ sc{COORDINATOR}s$ reply with a $ sc{TENTATIVE} sc{VOTE}( ldots, x)$. Each $ sc{CLIENT}$ waits for the tentative votes until they reach a majority. If a majority is not reached, retry. | Phase 2: If a majority is reached, the $ sc{CLIENT}s$ send $ sc{PLEASE} sc{VOTE}$, and the $ sc{COORDINATOR}s$ actually vote. Their actual votes would be the same as their respective tentative votes. Each $ sc{CLIENT}$ waits for the votes until they reach a majority, and then adopt the majority number. | . Back to Paxos . Our algorithm does look a bit different from the official Paxos. For one, the name of the agents are different. What we call $ sc{CLIENT}s$, Lamport calls $ sc{PROPOSER}s$; and $ sc{COORDINATOR}s$, $ sc{ACCEPTOR}s$. . Besides that, there are protocol differences too. . Firstly, the $ sc{COORDINATOR}s$ don&#39;t have to send the $ sc{TENTATIVE} sc{VOTE}( ldots)$ to everyone, they just need to send it to the $ sc{CLIENT}$ they agree with. This way we won&#39;t have every $ sc{CLIENT}s$ sending $ sc{PLEASE} sc{VOTE}$ at the same time, that would be inefficient. . After, we notice that the proposed number is unnecessarily sent multiple times in phase 1 and phase 2. The phase 1 is used to reach a majority, the proposed number is not actually important in that phase. So we remove the $x$ from $ sc{PROPOSAL}$; and in $ sc{TENTATIVE} sc{VOTE}$, instead voting for a number, they vote for a $ sc{CLIENT}$, by sending the tentative vote only to that $ sc{CLIENTS}$. Finally, after a client received a majority of tentative votes, it sends a $ sc{PLEASE} sc{VOTE}(x)$, so all the $ sc{COORDINATOR}s$ got that message will vote $x$. Of course, if a $ sc{COORDINATOR}$ has already voted in a previous round, it has to tell the $ sc{CLIENT}$, so it could pick the already voted $x$, otherwise its $ sc{PLEASE} sc{VOTE}(x)$ will be wasted, as the $ sc{COORDINATOR}s$ couldn&#39;t change their minds. . (The modified algorithm has slightly better property. In our algorithm, we just make sure a majority is still possible after each attempt; in Paxos, each round the $ sc{COORDINATOR}s$ that vote will all vote for the same number.) . With this little changes, we can map our algorithm back to Paxos: . Agents: . $ sc{CLIENT}$ =&gt; $ sc{PROPOSER}$ (which makes proposals) and $ sc{LEARNER}$ (which adopts the resulting number) | $ sc{COORDINATOR}$ =&gt; $ sc{ACCEPTOR}$ | . Messages: . $ sc{PROPOSAL}( #attempt, client_i)$ =&gt; $ sc{PREPARE}( #attempt, client_i)$ | $ sc{TENTATIVE} sc{VOTE}( #attempt, coord_i)$ =&gt; $ sc{PROMISE}( #attempt, coord_i)$ | $ sc{PLEASE} sc{VOTE}( #attempt, client_i, x)$ =&gt; $ sc{ACCEPT}( #attempt, client_i, x)$ | $ sc{VOTE}( #attempt, coord_i, x)$ =&gt; $ sc{ACCEPTED}( #attempt, coord_i, x)$ | .",
            "url": "https://explain.yshui.dev/distributed%20system/2020/09/20/paxos.html",
            "relUrl": "/distributed%20system/2020/09/20/paxos.html",
            "date": " • Sep 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "Here I try my best to explain algorithms. Partly for curious people, partly for my future self. . I will be utterly flustered if anyone can find this useful. . Also, if you find any mistakes please don&#39;t hesitate to open an issue. . . This website is powered by fastpages. .",
          "url": "https://explain.yshui.dev/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ &quot;sitemap.xml&quot; | absolute_url }} | .",
          "url": "https://explain.yshui.dev/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}